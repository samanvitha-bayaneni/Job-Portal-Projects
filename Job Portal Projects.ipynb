{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4335a424",
   "metadata": {},
   "source": [
    "# Projects to Build Based on Job Portals' Job Descriptions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf19f95",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A Python script that automates the process of collecting job descriptions from LinkedIn, Glassdoor, and Indeed job search results, and then uses a website (https://usellm.org/) to generate suggestions for relevant projects based on the job descriptions. The code utilizes the Selenium library to interact with web pages and collect job descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c552da3",
   "metadata": {},
   "source": [
    "## Steps to Follow\n",
    "\n",
    "- Import the necessary libraries, including os, pandas, requests, BeautifulSoup, time, and Selenium.\n",
    "- Set up the web driver for Firefox and define URLs for LinkedIn, Glassdoor, and Indeed job search results.\n",
    "- Create three functions for each job search website:` get_linkedin_projects`, `get_glassdoor_projects`, and `get_indeed_projects`.\n",
    "- In each function, automate the process of collecting job descriptions from the respective website.\n",
    "- Process the collected job descriptions, format them, and then send them to the website https://usellm.org/ for project suggestions.\n",
    "- Retrieve project suggestions from the website and print them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4c5aa",
   "metadata": {},
   "source": [
    "## Tools and Libraries Used\n",
    "\n",
    "- Python: The core programming language used for scripting.\n",
    "- Selenium: Used for web scraping and automating interactions with web pages.\n",
    "- BeautifulSoup: Used for parsing HTML content from web pages.\n",
    "- Pandas: Used for data manipulation and storage.\n",
    "- Requests: Used for making HTTP requests to web pages.\n",
    "- Time: Used for adding delays and sleep to manage web page interactions.\n",
    "- os: Used for working with the operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8e7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import os\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095ae737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/461kwq6d42j7t8d6yytb5nyw0000gp/T/ipykernel_51827/113299753.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Firefox(executable_path=r'/Users/samanvitha/Downloads/geckodriver 3')\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Firefox(executable_path=r'/Users/samanvitha/Downloads/geckodriver 3')\n",
    "#driver.get('http://inventwithpython.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba53e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_da = 'https://www.linkedin.com/jobs/search/?currentJobId=3697204625&f_E=1%2C2&f_T=340&f_TPR=r86400&geoId=102713980&keywords=Data%20Analyst&location=India&refresh=true&sortBy=R'\n",
    "glassdoor_da = 'https://www.glassdoor.co.in/Job/india-data-analyst-jobs-SRCH_IL.0,5_IN115_KO6,18.htm?fromAge=1'\n",
    "indeed_da = 'https://in.indeed.com/jobs?q=Data+Analyst&l=India&fromage=1&vjk=7b6d9046fa207bf4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827ee03",
   "metadata": {},
   "source": [
    "## `get_linkedin_projects(url)`\n",
    "\n",
    "- This function is designed to automate the process of collecting job descriptions from LinkedIn job search results and then generate project suggestions based on these descriptions.\n",
    "- It utilizes the Selenium library to interact with the LinkedIn job search page by navigating to the specified URL.\n",
    "- After loading the page, it identifies job descriptions by selecting elements with the class name 'base-card.relative.w-full' and iterates through them.\n",
    "- For each job listing, it clicks on the element to expand the job description, waits for a brief period (2 seconds), and then attempts to extract the job description text using the class 'description__text.description__text--rich.'\n",
    "- If the job description is successfully extracted, it is added to a list of details.\n",
    "- The function also simulates scrolling down the page to load more job listings, allowing it to collect multiple job descriptions.\n",
    "- After collecting the job descriptions, it formats them and sends them to an external website (https://usellm.org/) for project suggestion generation.\n",
    "- Finally, it prints the project suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65c66d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/461kwq6d42j7t8d6yytb5nyw0000gp/T/ipykernel_51827/4233837739.py:24: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n",
      "  driver.find_element_by_css_selector(\"input.p-2\").send_keys(summary + [\"Suggest major projects that I need to build for the above job descriptions and what tools I need to use. Maximum of three projects. Make sure the projects are relevant to the job description and have a high chnace of getting shortlisted for the jobs.\"], Keys.ENTER)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the job description provided, here are three relevant projects that you can consider building:\n",
      "\n",
      "1. **Automated Metrics Dashboard**: Develop an automated metrics dashboard using Microsoft Power BI to track and visualize key performance indicators (KPIs) and management information for the Information and Cyber Security function. This project will involve collecting relevant data, creating interactive visualizations, and enabling stakeholders to monitor and analyze security metrics in real-time.\n",
      "\n",
      "2. **Data Analysis and Insights**: Conduct data analysis on security-related datasets using tools like Microsoft Power BI. Identify trends, patterns, and anomalies in the data to provide actionable insights to the business. This project can involve analyzing security incident reports, user access logs, or other relevant datasets to identify areas for improvement and make data-driven recommendations.\n",
      "\n",
      "3. **Automation of Reporting Processes**: Streamline and automate the reporting processes within the Business Reporting and Governance vertical using tools like Power BI and scripting languages like Python or PowerShell. This project can involve automating the generation of daily reports required by senior leadership, improving data accuracy and timeliness, and creating self-service reporting tools for stakeholders.\n",
      "\n",
      "These projects demonstrate your skills in reporting, data analysis, automation, and visualization using Microsoft Power BI, which are relevant to the job description. They also showcase your ability to provide valuable insights, improve operational efficiency, and support decision-making processes.\n"
     ]
    }
   ],
   "source": [
    "def get_linkedin_projects(url):\n",
    "    driver.get(url)\n",
    "    details= [] \n",
    "    elements = driver.find_elements(By.CLASS_NAME,'base-card.relative.w-full')\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        sleep(2)\n",
    "        try:\n",
    "            about_jobs = driver.find_element(By.CLASS_NAME, 'description__text.description__text--rich').text   \n",
    "        except:\n",
    "            about_jobs ='NA'\n",
    "        details.append({'Job Description': about_jobs.replace('\\n', ' ')})\n",
    "        body = driver.find_element(By.TAG_NAME,\"body\")\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        sleep(1)\n",
    "    df=pd.DataFrame.from_dict(details)\n",
    "    all_projects = []\n",
    "    summary = []\n",
    "    for i in df['Job Description']:\n",
    "        i.strip('Show more')\n",
    "        summary.append(i)\n",
    "    driver.get('https://usellm.org/')\n",
    "    sleep(5)\n",
    "    driver.find_element_by_css_selector(\"input.p-2\").send_keys(summary + [\"Suggest major projects that I need to build for the above job descriptions and what tools I need to use. Maximum of three projects. Make sure the projects are relevant to the job description and have a high chnace of getting shortlisted for the jobs.\"], Keys.ENTER)\n",
    "    sleep(10)\n",
    "    input_string = driver.find_elements(By.CLASS_NAME,'whitespace-pre-wrap.mt-1')[2].text.strip()\n",
    "    #lines = input_string.split(\"\\n\")\n",
    "    #filtered_list = [item for item in lines if item != \"\"]\n",
    "    #all_projects.append(filtered_list[1:7])\n",
    "    print(input_string)\n",
    "get_linkedin_projects(linkedin_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12fdbd5",
   "metadata": {},
   "source": [
    "## `get_glassdoor_projects(url)`\n",
    "\n",
    "- This function automates the process of collecting job descriptions from Glassdoor job search results and then generates project suggestions based on these descriptions.\n",
    "- It uses Selenium to interact with the Glassdoor job search page by navigating to the specified URL.\n",
    "- It identifies job descriptions by selecting elements with the class 'd-flex.justify-content-between.p-std.jobCard' and iterates through them.\n",
    "- For each job listing, it clicks on the element to expand the job description, waits for a brief period (7 seconds), and then attempts to extract the job description text using the class 'JobDetails_jobDescription__6VeBn.JobDetails_blurDescription__fRQYh.'\n",
    "- Extracted job descriptions are added to a list.\n",
    "- Similar to the LinkedIn function, it formats the job descriptions and sends them to the external website for project suggestion generation.\n",
    "- Finally, it prints the project suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020882f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/461kwq6d42j7t8d6yytb5nyw0000gp/T/ipykernel_51827/2204342628.py:19: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n",
      "  driver.find_element_by_css_selector(\"input.p-2\").send_keys(summary + [\"Suggest major projects that I need to build for the above job descriptions and what tools I need to use. Maximum of three projects. Make sure the projects are relevant to the job description and have a high chnace of getting shortlisted for the jobs.\"], Keys.ENTER)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the job descriptions provided, here are three relevant projects that you can build to showcase your skills and increase your chances of getting shortlisted for the jobs:\n",
      "\n",
      "1. HR Analytics Dashboard:\n",
      "Develop an interactive dashboard using Tableau that provides insights into key HR metrics such as employee turnover, recruitment effectiveness, performance management ratings, and training & development impact. Utilize data visualization techniques to highlight trends, identify patterns, and present actionable insights for HR strategy and decision-making.\n",
      "\n",
      "Tools: Tableau, SQL\n",
      "\n",
      "2. Financial Statement Analysis Tool:\n",
      "Create a tool using Python or R that automates the process of analyzing financial statements and generating key financial ratios. The tool should be able to import financial data, calculate ratios such as liquidity, solvency, and profitability, and provide visualizations or reports for easy interpretation. Additionally, incorporate a feature to compare financial data across different banks or companies.\n",
      "\n",
      "Tools: Python or R, Financial modeling libraries (e.g., pandas, numpy)\n",
      "\n",
      "3. Customer Segmentation and Personalization:\n",
      "Develop a machine learning model using Python or R to segment customers based on their financial needs, behaviors, and interactions with products and services. Use clustering algorithms (e.g., k-means, hierarchical clustering) to identify distinct customer segments. Then, build a recommendation system that suggests personalized product offerings or marketing strategies for each segment, aiming to enhance customer experience and drive business growth.\n",
      "\n",
      "Tools: Python or R, Machine learning libraries (e.g., scikit-learn, caret)\n",
      "\n",
      "Remember to tailor the projects to the specific requirements mentioned in each job description and highlight the relevant skills and technologies you used in your CV or application. Good luck with your applications!\n"
     ]
    }
   ],
   "source": [
    "def get_glassdoor_projects(url):\n",
    "    driver.get(url)\n",
    "    elements= driver.find_elements(By.CLASS_NAME, 'd-flex.justify-content-between.p-std.jobCard')\n",
    "    diction={'j_d':[]}\n",
    "    for element in elements[:6]:\n",
    "        element.click()\n",
    "        sleep(7)\n",
    "        try:\n",
    "             diction['j_d'].append(driver.find_elements(By.CLASS_NAME,\"JobDetails_jobDescription__6VeBn.JobDetails_blurDescription__fRQYh\")[0].text)\n",
    "        except:\n",
    "            diction['j_d'].append(\"NA\")\n",
    "    all_projects = []\n",
    "    summary = []\n",
    "    for i in diction['j_d']:\n",
    "        i.strip('Show more')\n",
    "        summary.append(i)\n",
    "    driver.get('https://usellm.org/')\n",
    "    sleep(5)\n",
    "    driver.find_element_by_css_selector(\"input.p-2\").send_keys(summary + [\"Suggest major projects that I need to build for the above job descriptions and what tools I need to use. Maximum of three projects. Make sure the projects are relevant to the job description and have a high chnace of getting shortlisted for the jobs.\"], Keys.ENTER)\n",
    "    sleep(10)\n",
    "    input_string = driver.find_elements(By.CLASS_NAME,'whitespace-pre-wrap.mt-1')[2].text.strip()\n",
    "    # all_projects.append(input_string)\n",
    "    # all_projects\n",
    "    print(input_string)\n",
    "get_glassdoor_projects(glassdoor_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90153761",
   "metadata": {},
   "source": [
    "## `get_indeed_projects(url)`\n",
    "\n",
    "- This function automates the process of collecting job descriptions from Indeed job search results and then generates project suggestions based on these descriptions.\n",
    "- It uses Selenium to interact with the Indeed job search page by navigating to the specified URL.\n",
    "- After loading the page, it uses BeautifulSoup to parse the HTML content.\n",
    "- It identifies job descriptions by selecting elements with the class 'job-snippet' and extracts the job description text.\n",
    "- Extracted job descriptions are added to a dictionary.\n",
    "- As with the other functions, it formats the job descriptions and sends them to the external website for project suggestion generation.\n",
    "- Finally, it prints the project suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd04a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/461kwq6d42j7t8d6yytb5nyw0000gp/T/ipykernel_51827/3470187625.py:26: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n",
      "  driver.find_element_by_css_selector(\"input.p-2\").send_keys(summary + [\"Suggest major projects that I need to build for the above job descriptions and what tools I need to use. Maximum of three projects. Make sure the projects are relevant to the job description and have a high chnace of getting shortlisted for the jobs.\"], Keys.ENTER)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the job descriptions provided, here are three relevant projects that you can consider for your portfolio:\n",
      "\n",
      "1. Data Pipeline Development:\n",
      "Develop a data pipeline to import and transform data from various sources into a centralized data warehouse or data lake. Use tools like Apache Airflow or AWS Glue to schedule and automate the data ingestion and transformation processes. Implement data quality checks and validation processes to ensure data accuracy, consistency, and reliability.\n",
      "\n",
      "2. Data Visualization and Insights Generation:\n",
      "Create interactive dashboards and reports using Power BI or other visualization tools to analyze the data and generate valuable insights. Focus on showcasing your ability to extract meaningful information from data and present it in a visually appealing and easily understandable format. Include features like drill-downs, filters, and dynamic visualizations to enhance user experience.\n",
      "\n",
      "3. Data Governance and Compliance:\n",
      "Design and implement data governance processes to ensure compliance with data privacy regulations (e.g., GDPR) and maintain data security. Develop data cataloging and metadata management solutions to improve data discoverability and accessibility. Demonstrate your understanding of data governance best practices and the ability to establish policies and guidelines for data usage within an organization.\n",
      "\n",
      "By showcasing these projects in your portfolio, you can demonstrate your skills and experience in data engineering, data analysis, data visualization, and data governance, which are highly relevant to the job descriptions provided.\n"
     ]
    }
   ],
   "source": [
    "def get_indeed_projects(url):\n",
    "    driver.get(url)\n",
    "    sleep(10)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    def get_description(Data):\n",
    "        try:\n",
    "            job_description= soup.find_all('div',class_=\"job-snippet\")\n",
    "            Job_des=[]\n",
    "            for i in range(len(job_description)):\n",
    "                name=job_description[i].text.strip('\\n')\n",
    "                name1=name.strip('\\uf0a7')\n",
    "                Job_des.append(name1)  \n",
    "        except:\n",
    "            Job_des= \"NA\"\n",
    "        return Job_des\n",
    "    Job_des=get_description(soup)\n",
    "    Dict_data={'Job-Description' :Job_des}\n",
    "    all_projects = []\n",
    "    summary = []\n",
    "    for i in Dict_data['Job-Description']:\n",
    "        i.strip('Show more')\n",
    "        summary.append(i)\n",
    "    driver.get('https://usellm.org/')\n",
    "    sleep(5)\n",
    "    driver.find_element_by_css_selector(\"input.p-2\").send_keys(summary + [\"Suggest major projects that I need to build for the above job descriptions and what tools I need to use. Maximum of three projects. Make sure the projects are relevant to the job description and have a high chnace of getting shortlisted for the jobs.\"], Keys.ENTER)\n",
    "    sleep(10)\n",
    "    input_string = driver.find_elements(By.CLASS_NAME,'whitespace-pre-wrap.mt-1')[2].text.strip()\n",
    "    #all_projects.append(input_string)\n",
    "    #all_projects\n",
    "    print(input_string)\n",
    "get_indeed_projects(indeed_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6d4d4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The code automates the process of collecting job descriptions from popular job search websites and then generates project suggestions based on the collected descriptions using an external website. This can be helpful for job seekers looking to gain insights into the skills and projects that are relevant to specific job positions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b01d6b",
   "metadata": {},
   "source": [
    "## Future Work Ideas\n",
    "\n",
    "- Enhance Project Suggestions: Improve the project suggestion generation process to provide more detailed and relevant project ideas.\n",
    "- Data Storage: Implement a data storage system to save job descriptions and project suggestions for further analysis or reference.\n",
    "- Error Handling: Add robust error handling to the code to manage unexpected situations gracefully.\n",
    "- Automation Pipeline: Create a pipeline that regularly scrapes job descriptions and generates project suggestions, automating the job search and project idea generation process.\n",
    "- User Interface: Develop a graphical user interface (GUI) for the code to make it more user-friendly for non-technical users.\n",
    "- Job Matching: Extend the code to match job descriptions with available online courses or resources to further help job seekers improve their qualifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
